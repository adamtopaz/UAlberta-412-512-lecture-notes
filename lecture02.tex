\section{Lecture 2}

In this course, a \emph{ring} will always be \emph{commutative} with $1$.
If $A$ is a ring, then an $A$-algebra will be a ring endowed with a \emph{structure morphism} $A \to B$, which will almost always be left implicit.
A morphism $B_{1} \to B_{2}$ of $A$-algebras is a morphism of rings which is compatible with the structure morphisms in the obvious way.

Recall that $A[X_{1},\ldots,X_{n}]$, the polynomial ring in $n$ variables, is the free $A$-algebra on the set $\{X_{1},\ldots,X_{n}\}$.
Explicitly, what this means is that any function $f : \{X_1,\ldots,X_n\} \to B$ extends in a unique way to a morphism of $A$-algebras $A[X_1,\ldots,X_n] \to B$.
Thus, if $B$ is an $A$-algebra and $b_{1},\ldots,b_{n} \in B$ are given, then there is a unique morphism of $A$-algebras
\[ A[X_{1},\ldots,X_{n}] \to B \]
satisfying $X_{i} \mapsto b_{i}$.
This map is called \emph{evaluation} at $b_{1},\ldots,b_{n}$, and will be denoted in the usual way as
\[ f(X_{1},\ldots,X_{n}) \mapsto f(b_{1},\ldots,b_{n}). \]
If we express a polynomial $f$ as $f = \sum_{i} a_i X^i$, where $i$ is a multiindex, then $f(b_1,\ldots,b_n) = \sum_i a_i b^i$.


\begin{definition}
  Let $A$ be a ring and $B$ an $A$-algebra.
  An element $b \in B$ is called \emph{integral} over $A$ provided that there exists some \emph{monic} nonzero polynomial $f \in A[X]$ such that $f(b) = 0$.
  We say that $B$ is \emph{integral over $A$} if all the elements of $B$ are integral over $A$.
\end{definition}

If $b_{1},\ldots,b_{n} \in B$ are given, then the image of the morphism $A[X_{1},\ldots,X_{n}] \to B$ will be denoted by $A[b_{1},\ldots,b_{n}]$.
This is precisely the $A$-subalgebra of $B$ which is generated by $b_{1},\ldots,b_{n}$.
Recall that the algebra $B$ is said to be \emph{of finite type} provided that $B$ is finitely generated, meaning that $B = A[b_{1},\ldots,b_{n}]$ for some choice of $b_{1},\ldots,b_{n} \in B$.
A stronger notion of finiteness is being a \emph{finite} algebra, which means that $B$ is finitely generates as an $A$-module.

\begin{lemma}[Transitivity of Finiteness]\label{lemma:transitivity of finiteness}
  Let $B$ be a finite $A$-algebra and let $C$ be a finitely-generated $B$-module.
  Then $C$ is a finitely-generated $A$-module.
\end{lemma}
\begin{proof}
	Suppose $\{a_i\colon i= 1,\cdots, m\}$ is a generator of $A$ as a $B$-module and $\{b_i\colon i= 1,\cdots, n\}$ is a generator of $B$ as a $C$-module. Then for any $b\in B$, there exist $c_i(b)\in C$ for $i = 1,\cdots, n$ such that $b = \sum_i c_i(b)b_i$. Next, for an arbitrary $a\in A$, there exist $b_j'\in B$ for $j = 1, \cdots, m$ such that \[a = \sum_{j = 1}^m b_j' a_j = \sum_{j = 1}^m \left(\sum_{i=1}^n c_i(b_j')\cdot b_i\right)\cdot a_j = \sum_{j = 1}^m \sum_{i=1}^n c_i(b_j')\cdot b_ia_j,\]
	which implies $\{b_ia_j\}$ forms a finite generator of $A$ over $C$ and in particular $A$ is a finitely generated $C$-module. 
\end{proof}

\begin{proposition}
  Let $B$ be an $A$-algebra.
  Let $b_{1},\ldots,b_{n} \in B$ be given.
  Then $b_{1},\ldots,b_{n}$ are all integral over $A$ if and only if $A[b_{1},\ldots,b_{n}]$ is finite as an $A$-algebra.
\end{proposition}
\begin{proof}
  First we focus on the forward direction.
  Argue by induction on $n$.
  The case $n = 0$ is trivial.
  In general, note that $A[b_{1},\ldots,b_{n+1}] = A[b_{1},\ldots,b_{n}][b_{n+1}]$.
  By induction $A[b_{1},\ldots,b_{n}]$ is finite over $A$, so by Lemma~\ref{lemma:transitivity of finiteness} it suffices to assume $n = 1$, and put $b = b_{1}$.
  In this case, let $g$ be a nonzero monic polynomial over $A$ such that $g(b) = 0$.
  Note that $A[b]$ is a quotient of $A[X]/(g)$, which is easily seen to be finitely-generated as a module over $A$, as it is generated by the images of $1,X,\ldots,X^{d-1}$ where $d = \deg(g)$. In fact, for any $f\in A[X]$, it is easy to see that there is a $h\in A[X]$ of $\deg(h) < d$, hence a $A$-linear combination of $1,X,\ldots,X^{d-1}$, such that $f\equiv h \ \operatorname{mod}(g)$ by a division algorithm. 
  The same therefore holds for $A[b]$.

  Conversely, suppose that $A[b_{1},\ldots,b_{n}]$ is generated as an $A$-module by the elements $c_{1},\ldots,c_{k}$, and let $b \in A[b_{1},\ldots,b_{n}]$ be arbitrary.
  We have for every $i$,
  \[ b \cdot c_{i} = \sum_{j} a_{i,j} c_{j}, \ \ a_{ij} \in A. \]
  In particular, letting $I$ denote the $k \times k$ identity matrix and $M = (a_{ij})$, we have
  \[ (b \cdot I - M) \cdot (c_{1},\ldots,c_{k})^{t} = 0. \]
  Let $L$ denote the adjugate of $N := b \cdot I - M$ and recal that $L \cdot N = \det(N) \cdot I$ to deduce that
  \[ 0 = L \cdot N \cdot (c_{1},\ldots,c_{k})^{t} = \det(N) \cdot (c_{1},\ldots,c_{k})^{t}, \]
  and thus $\det(N) \cdot c_{i} = 0$ for all $i$.
  As $c_{1},\ldots,c_{k}$ generate $A[b_{1},\ldots,b_{n}]$, it follows that $\det(N)$ annihilates all of $A[b_{1},\ldots,b_{n}]$, and thus $\det(N) = 0$ since $\det(N)$ annihilates $1$.
  But $\det(N) = \det(b \cdot I - M)$ is a nonzero monic polynomial in $b$ with coefficients in $A$, so that $b$ is integral over $A$, as contended.
\end{proof}

In particular, this proposition shows that if $b_{1},b_{2} \in B$ are integral over $A$, then so is every other element $b$ of $A[b_{1},b_{2}]$, since $A[b_{1},b_{2}] = A[b,b_{1},b_{2}]$.
It follows that the sums and products of any integral elements are again integral, and thus the collection of all elements of $B$ which are integral over $A$ forms a subalgebra of $B$.

Another consequence is the following useful proposition.
\begin{proposition}
  Suppose that $B$ is an $A$-algebra and $C$ is a $B$-algebra.
  If $B$ is integral over $A$ and $C$ is integral over $B$ then $C$ is integral over $A$.
\end{proposition}
\begin{proof}
  Let $c \in C$ be given, and find an equation of the form
  \[ c^{n} + b_{1} c^{n-1} + \cdots + b_{n} = 0, \ \ b_{i} \in B. \]
  Put $T := A[b_{1},\ldots,b_{n}]$ and note that $c$ is integral over $T$, while $T$ is finite over $A$.
  Since $T[c]$ is finite over $T$, transitivity of finiteness implies that $T[c]$ is finite over $A$ hence $c$ is integral over $A$.
\end{proof}

\begin{definition}
  Let $B$ be an $A$-algebra.
  The set
  \[ \bar A = \{b \in B \ | \ \text{$b$ is integral over $A$}\}, \]
  which is an $A$-subalgebra of $B$ as noted above, is the \emph{integral closure} of $A$ in $B$.
  Note that the structure map $f : A \to B$ factors as
  \[ A \to \image(f) \subset \bar A \subset B. \]
\end{definition}

We easily see that the integral closure is an idempotent operation, meaning that the integral closure of the integral closure is the integral closure.
Also, the integral closure of $A$ is integral over $A$.
If $A \subset B$ is an extension of rings, then we shall say that $A$ is \emph{integrally closed} in $B$ provided that $A$ agrees with its integral closure in $B$.
The special case where $A$ is a domain and $B$ is its fraction field is particularly important, as we now discuss.

\begin{definition}
  Let $A$ be a domain with fraction field $K$.
  We say that $A$ is \emph{normal} provided that $A$ is integrally closed in $K$.
  If $L$ is an extension of $K$, then the \emph{normalization of $A$ in $L$} is the integral closure of $A$ in $L$.
  When $L = K$, we say ``the normalization of $A$'' instead of ``the normalization of $A$ in $K$.''
\end{definition}

\begin{example}
  Any UFD is normal.
  Suppose that $A$ is a UDF and that $a,b \in A$ are two elements with $b \neq 0$.
  Suppose that $a/b$ is integral over $A$, so it satisfies some equation of the form
  \[ (a/b)^{n} + c_{1} (a/b)^{n-1} + \cdots + c_{n} = 0, \ \ c_{i} \in A. \]
  Multiply by $b^{n}$ to obtain
  \[ a^{n} + c_{1} b a^{n-1} + \cdots + c_{n} b^{n} = 0. \]
  If $\pi$ is a prime element which divides $b$, this shows that $\pi$ also divides $a^{n}$ hence it divides $a$ as well.
  In particular, this shows that $b$ divides $a$, and thus $a/b \in A$, as required.
\end{example}

For the rest of this lecture, we focus on the following special situation.
We are given a normal domain $A$ with fraction field $K$, and a finite extension $L|K$.
Write $B$ for the normalization of $A$ in $L$.

\begin{lemma}
  One has $B \cap K = A$.
\end{lemma}
\begin{proof}
  The inclusion $A\subset B\cap K$ is trivial. 
  For the other direction, we have $B\cap K = \{x\in K\colon x \text{ is integral over } A\} = A$. 
  The second equality is the definition of normality. 
\end{proof}

\begin{lemma}
  Any element of $L$ has the form $x/y$ with $x \in B$ and $y \in A$.
\end{lemma}
\begin{proof}
  Let $t \in L$ be given.
  As $L|K$ is finite, hence algebraic, there is a monic equation of the form
  \[ t^{n} + w_{1} t^{n-1} + \cdots + w_{n} = 0, \ \ w_{i} \in K. \]
  Write $w_i = b_i/c_i$ for all $i$ where $b_i, c_i\in A$. We have $t^n + \sum_{i=1}^n t^{n-i}b_i/c_i = 0$. Multiply both sides by $\prod_i c_i$, we obtain an equation of the form
  \[ a_{n} t^{n} + \cdots + a_{1} t + a_{0} = 0, \ \ a_{i} \in A. \]
  Multiply again by $a_{n}^{n-1}$ to obtain an integral equation for $a_{n} t$, namely 
  \[(a_n t)^n + a_{n-1}(a_nt)^{n-1} +\cdots + a_1a_n^{n-2}(a_nt) + a_n^{n-1}a_0 = 0,\]
  which implies that $a_{n} t \in B$.
  The claim follows.
\end{proof}

\begin{proposition}
  Let $x \in L$ be given, and let $p$ denote the minimal polynomial of $x$ over $K$.
  Then $x$ is integral over $A$ if and only if the coefficients of $p$ are elements of $A$.
\end{proposition}
\begin{proof}
  Since minimal polynomials are by definition monic, the reverse implication is trivial by definition.
  Conversely, suppose that $x \in L$ is indeed integral over $A$, and let $q$ be a monic polynomial with coefficients in $A$ such that $q(x) = 0$.
  Let $B$ denote the normalization of $A$ in $L$, and observe that $B \cap K = A$.
  Since $p$ is the minimal polynomial, it follows that $p | q$ in $K[X]$, and thus every root of $p$ (in some algebraic closure) is also integral.
  Letting $y_{1},\ldots,y_{n}$ denote such roots (with multiplicity) of $p$, we have
  \[ p(X) = \prod_{i} (X - y_{i}) \]
  while all $y_{i}$ are contained in the normalization of $A$ in $L$.
  But the coefficients of $p$ are (integral) polynomial functions of its roots, so it follows that the coefficients of $p$ are all in $B$.
  On the other hand, the coefficients of $p$ are elements of $K$.
  Since $A = K \cap B$, it follows that $p$ indeed has coefficients in $A$.
\end{proof}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
